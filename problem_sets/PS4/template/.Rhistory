detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c(),  pkgTest)
setwd("/Users/jasminlim/Documents/GitHub/QTM200Spring2020/problem_sets/PS2/")
# a)
bribe_study <- matrix(c(14, 6, 7, 7, 7, 1), byrow = T, nrow = 2)
bribe_study
rownames(bribe_study) <- c("Upper class", "Lower class")
colnames(bribe_study) <- c("Not stopped", "Bribe requested", "Stopped/given warning")
bribe_study
expected_count <- bribe_study
bribe_study
View(detachAllPackages)
lapply(c(),  pkgTest)
positions <- order(planets_df$diameter)
# Vectors of same length
name <- c("Mercury", "Venus", "Earth", "Mars", "Jupiter", "Saturn", "Uranus", "Neptune")
type <- c("Terrestrial planet", "Terrestrial planet", "Terrestrial planet",
"Terrestrial planet", "Gas giant", "Gas giant", "Gas giant", "Gas giant")
diameter <- c(0.382, 0.949, 1, 0.532, 11.209, 9.449, 4.007, 3.883)
rotation <- c(58.64, -243.02, 1, 1.03, 0.41, 0.43, -0.72, 0.67)
rings <- c(FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)
planets_df <- data.frame(name, type, diameter, rotation, rings)
str(planets_df)
# Selecting entries
planets_df[1,2] # Row 1, Col 2
planets_df[1:3, 1:3]
planets_df[1:5, "type"] # Also access by name
planets_df$name # dollar sign is the easiest method
planets_df[planets_df$rings, ] # selecting planets with rings
subset(planets_df, subset = rings) # easier way: make a subset
subset(planets_df, subset = type == "Terrestrial planet")
a <- c(10, 1000, 100)
order(a)
a[order(a)] # reshuffling a
positions <- order(planets_df$diameter)
planets_df[positions,]
my_vector <- 1:10;
my_vector <- 1:10
my_vector <- 1:10
my_matrix <- matrix(1:9, nrow = 3)
my_list <- list(my_vector, my_matrix)
my_list
# Option 1
names(my_list) <- c("vector", "matrix")
my_list
# Or
my_list <- list(ugh = my_vector, bye = my_matrix)
my_list
# Selecting elements
my_list[[2]]
# or
my_list[[bye]]
# or
my_list[["bye"]]
my_list[["bye"]][2, 3]
calories <- c(2430, 3250, 1820, 1750, 3420)
calories
names(calories) <- days_of_week
calories
calories <- c(2430, 3250, 1820, 1750, 3420)
calories
days_of_week <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(calories) <- days_of_week
calories
calories2 <- c(2330, 3800, 2520, 2750, 1420)
mean(calories2[2:4])
mean(calories2[2, 3, 4])
calories_weeks <- matrix(c(calories, calories2), nrow = 2, byrow = T)
calories_weeks
colnames(calories_weeks) <- days_of_week
calories_weeks
?colname
?colnames
rownames(calories_weeks) <- c("This week", "Last week")
calories_weeks
Two_Weeks_Ago <- c(4120, 2200, 1850, 2500, 2700)
calories_weekly <- rbind(calories_weeks, Two_Weeks_Ago )
calories_weekly
total_cal_by_week <- rowSums(calories_weekly)
total_cal_by_week
total_cal_by_day <- colSums(calories_weekly) # Summing the columns' total calories
total_cal_by_day
?name
?names
calories <- c(2430, 3250, 1820, 1750, 3420)
calories
days_of_week <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(calories) <- days_of_week
calories
calories2 <- c(2330, 3800, 2520, 2750, 1420)
mean(calories2[2:4])
mean(calories2[2, 3, 4])
calories_weeks <- matrix(c(calories, calories2), nrow = 2, byrow = T)
calories_weeks
colnames(calories_weeks) <- days_of_week
calories_weeks
rownames(calories_weeks) <- c("This week", "Last week")
calories_weeks
Two_Weeks_Ago <- c(4120, 2200, 1850, 2500, 2700)
calories_weekly <- rbind(calories_weeks, Two_Weeks_Ago) # Binding new vector two_weeks_ago to the matrix
calories_weekly
total_cal_by_week <- rowSums(calories_weekly) # Summing the rows' total calories
total_cal_by_week
total_cal_by_day <- colSums(calories_weekly) # Summing the columns' total calories
total_cal_by_day
setwd("/Users/jasminlim/Documents/QTM 150/")
arrests <- USArrests.csv
arrests <- read.csv("USArrests.csv")
View(arrests)
?head
head(arrests, 10)
str(arrests)
summary(arrests)
arrests[order(arrests$Murder,)]
arrests[order(arrests$Murder),]
arrests[order(arrests$Rape),]
arrests[order(arrests$Assault),]
plot(arrests$UrbanPop, arrests$Rape)
rape_urban <- plot(arrests$UrbanPop, arrests$Rape)
cor(rape_urban)
?cor
cor(arrests$Rape~arrests$UrbanPop)
rape_urban <- plot(arrests$UrbanPop, arrests$Rape)
# b)
Murder_Rape <- data.frame(arrests$Murder, arrests$Rape)
Murder_Rape
View(Murder_Rape)
View(arrests)
# b)
Murder_Rape <- data.frame(arrests$Murder, arrests$Rape, arrests$State)
Murder_Rape
# b)
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape)
Murder_Rape
# c)
Total <- arrests$Murder + arrests$Rape
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape, total)
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape, Total)
Murder_Rape
Murder_Rape[order(Murder_Rape$Total),]
# d)
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total),]
Murder_Rape[10]
Murder_Rape[10,]
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
Murder_Rape[-16]
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
Murder_Rape[-16,]
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
Murder_Rape[50-16,]
?order
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total, decreasing = T)]
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total, decreasing = T),]
Murder_Rape[16,]
# d)
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total),]
Murder_Rape[10,]
# a)
rape_urban <- plot(arrests$UrbanPop, arrests$Rape) # Plot for Rape rate vs. UrbanPop rate
# b)
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape) # Creating new dataset with Murder, Rape, and State names
Murder_Rape
# b)
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape) # Creating new dataset with Murder, Rape, and State names
Murder_Rape
View(Murder_Rape)
c. Create a new variable within the Murder_Rape dataset called Total showing the sum of Murder and Rape rates.
In other words, your dataset should be 50 rows x 4 columns after creating Total variable.
# c)
Total <- arrests$Murder + arrests$Rape
Murder_Rape <- data.frame(arrests$State, arrests$Murder, arrests$Rape, Total)
Murder_Rape
View(Murder_Rape)
# d)
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total),]
e. Finally, which state is ranked  SIXTEENTH HIGHEST Total rate of Murder and Rape combined?
# e)
Murder_Rape <- Murder_Rape[order(Murder_Rape$Total, decreasing = T),] # Ordering in descending order
Murder_Rape[16,] # South Carolina
source('~/Documents/QTM 150/Quiz3.R')
cars
mean(cars$dist)
knitr::opts_chunk$set(echo = TRUE)
read.csv("LifetimeBoxOffice.csv")
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
knitr::opts_chunk$set(echo = TRUE)
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
str(LBO)
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
knitr::opts_chunk$set(echo = TRUE)
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
str(LBO) # LBO has 200 observations and 4 variables
knitr::opts_chunk$set(echo = TRUE)
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
?head
?head(LBO, 10)
head(LBO, 10)
View(LBO)
3. Print only the movies that earned over a total of one billion dollars of LifetimeGross.
LBO[LBO$LifeTimeGross > 1000000000]
LBO[LBO$LifeTimeGross > 1000000000]
LBO[LBO$LifeTimeGross > 1000000000,]
LBO[,LBO$LifeTimeGross > 1000000000]
LBO[,LBO$LifetimeGross > 1000000000]
LBO[LBO$LifetimeGross > 1000000000]
LBO[LBO$LifetimeGross > 1000000000]
LBO[LBO$LifetimeGross > 1000000000,]
movies2019 <- subset(LBO, subset = Year == "2019")
movies2019[2019$LifetimeGross > 1000000000,]
movies2019 <- subset(LBO, subset = Year == "2019")
movies2019[movies2019$LifetimeGross > 1000000000,]
movies2019 <- subset(LBO, subset = Year == "2019") # Making subset of 2019 movies in Top 200
movies2019 <- subset(LBO, subset = Year == "2019") # Making subset of 2019 movies in Top 200
movies2019 <- subset(LBO, subset = Year == "2019") # Making subset of 2019 movies in Top 200
movies2019
mean(LBO$LifetimeGross) # Mean =
sd(LBO$LifetimeGross) # SD =
cor(LBO$LifetimeGross,LBO$Year)
knitr::opts_chunk$set(echo = TRUE)
plot(LBO$LifetimeGross ~ LBO$Year) # Plot LifetimeGross vs. Year
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
0. Import the dataset and store in a data frame called LBO.
```{r}
LBO <- read.csv("LifetimeBoxOffice.csv") # Storing dataset into variable LBO
1. How many total observations and variables are included in LBO?
```{r}
str(LBO) # LBO has 200 observations and 4 variables
2. Print only the top 10 movies, LifetimeGross and Year for each movie.
```{r}
head(LBO, 10) # Printing first 10 movies
```
3. Print only the movies that earned over a total of one billion dollars of LifetimeGross.
```{r}
LBO[LBO$LifetimeGross > 1000000000,] # Printing movies that made over one billion dollars
4. Which movies released in 2019 made this list of top 200 movies? Print only the movies released in 2019.
```{r}
movies2019 <- subset(LBO, subset = Year == "2019") # Making subset of 2019 movies in Top 200
movies2019
5. What is the mean and the standard deviation of LifetimeGross?
```{r}
mean(LBO$LifetimeGross) # Mean = $853,441,585
sd(LBO$LifetimeGross) # SD = $3,453,57,279
```
6. Generate an appropriate plot showing LifetimeGross (response variable) by Year (explanatory variable). Describe in your own words the relationship between the two variables.
```{r}
plot(LBO$LifetimeGross ~ LBO$Year) # Plot LifetimeGross vs. Year
```{r setup, include=FALSE}
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
dim(gss) #This dataset contains 53474 rows and 14 variables
set.seed(1234) #generating a random number sequence
gss100<-gss[sample(nrow(gss),100),] #store 100 observations into an object called gss100
dim(gss100)
# get the working directory
getwd() #be sure to check your working directory!
# save a new dataset in your working directory
# write.csv(dataset,"working directory/givendataname.datatype")
# or write.csv(dataset, "name.csv")
write.csv(gss100, "smallgss.csv")
gss100<-gss[sample(nrow(gss),100),] #store 100 observations into an object called gss100
dim(gss100)
gss100<-gss[sample(nrow(gss),100),] #store 100 observations into an object called gss100
dim(gss100)
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
dim(gss) #This dataset contains 53474 rows and 14 variables
dim(gss) #This dataset contains 53474 rows and 14 variables
set.seed(1234) #generating a random number sequence
gss100<-gss[sample(nrow(gss),100),] #store 100 observations into an object called gss100
# get the working directory
getwd() #be sure to check your working directory!
write.csv(gss100, "smallgss.csv")
names(gss100) #get variable names
dim(gss100) # the number of observations and variables
summary(gss100)
head(gss100)  # print the first six observations
sum(is.na(gss$age)) #print a total number of missing values of age in the original dataset
sum(is.na(gss100$age)) #print a total number of missing values of age in the smaller dataset we created
dataframe is a matrix, each variable is a vector
```{r}
#dataset[row, column]
gss100[1,2]
# dataset[rows, columns]
gss100[1:5, c(2,5)]
#dataset[row, column]
gss100[1,2]
# dataset[rows, columns]
gss100[1:5, c(2,5)]
#dataset[row, column]
gss100[1,2]
# dataset[rows, columns]
gss100[1:5, c(2,5)]
#dataset$variable, the whole column
gss100[,7]
gss100$marital
# dataset$variable[rows]
gss100$marital[1:10]
#dataset[row, column]
gss100[1,2]
# dataset[rows, columns]
gss100[1:5, c(2,5)]
#dataset$variable, the whole column
gss100[,7]
gss100$marital
# dataset$variable[rows]
gss100$marital[1:10]
top200 <- read.csv("Top200Movies_2019.csv")
top200 <- read.csv("Top200Movies_2019.csv")
top200 <- read.csv("Top200Movies_2019.csv")
dim(top200)
str(top200)
head(top200)
tail(top200)
View(top200)
?sez
?seq
top200["Worldwide_m" > 1000,]
top200["Worldwide_m" > 1000,]
new <- top200["Worldwide_m" > 1000,]
new
new <- top200[top200$Worldwide_m > 1000,]
new[order(new, top200$Worldwide_m)]
new[order(new, new$Worldwide_m)]
new[order(new$Worldwide_m)]
new[order(new$Worldwide_m),]
new[order(new$Domestic_m),]
new[order(new$Foreign_m),]
top200[8]
top200[8,]
new[8,]
top200$domestic_percent = top200$Domestic_m / top200$Worldwide_m * 100
?order
# b)
new_df <- top200[order(top200$domestic_percent),] decreasing = T)
# b)
new_df <- top200[order(top200$domestic_percent),] decreasing = T]
# b)
new_df <- top200[order(top200$domestic_percent, decreasing = T),]
View(new_df)
# b)
descend_percent <- top200[order(top200$domestic_percent, decreasing = T),]
top25 <- head(descend_percent, 25)
View(top25)
top25 <- top25[order(top25$Domestic_m),]
top200 <- read.csv("Top200Movies_2019.csv")
dim(top200)
str(top200)
head(top200)
tail(top200)
new <- top200[top200$Worldwide_m > 1000,]
new[order(new$Foreign_m),]
new[8,]
GO BACK TO QUESTION 4!!!
a. Create a new variable within the top200 data frame (i.e., add a new column) called
"domestic_percent" representing the percentage (%) of domestic earnings out of Worldwide earnings
for each movie. For example, the value for Frozen II should be 32.98399.
# a)
top200$domestic_percent = top200$Domestic_m / top200$Worldwide_m * 100
b. Sort the entire data frame in the DESCENDING order of "domestic_percent" column.
# b)
descend_percent <- top200[order(top200$domestic_percent, decreasing = T),]
# c)
top25 <- head(25)
top25 <- order[top25$domestic_m, descending = T]
top25 <- order[top25$domestic_m, descending = T,]
top25 <- top25[order(top25$domestic_m, descending = T),]
# c)
top25 <- head(25)
# c)
top25 <- head(top200)
top25 <- top25[order(top25$domestic_m, descending = T),]
View(top25)
# c)
top25 <- head(top200, 25)
top25 <- top25[order(top25$domestic_m, descending = T),]
high_percent <- top25[order(top25$domestic_m, descending = T),]
top25 <- top25[order(top25$domestic_m, decreasing = T),]
top25 <- top25[order(top25$domestic_m, decreasing = T),]
top25 <- top25[order(top25$Domestic_m, decreasing = T),]
top25[1,]
#d)
plot(top200$Worldwide_m, top200$Domestic_m)
plot(top200$Worldwide_m, top200$Foreign_m)
e. Which does a better job predicting the worldwide earnings, domestic or foreign earning?
cor(top200$Worldwide_m, top200$Domestic_m)
cor(top200$Worldwide_m, top200$Foreign_m)
#d)
plot(top200$Domestic_m, top200$Worldwide_m)
plot(top200$Foreign_m, top200$Worldwide_m)
e. Which does a better job predicting the worldwide earnings, domestic or foreign earning?
cor(top200$Domestic_m, top200$Worldwide_m)
cor(top200$Foreign_m, top200$Worldwide_m)
top200[order(top200$Domestic_m, decreasing = T).]
top200[order(top200$Domestic_m, decreasing = T),]
agh <- top200[order(top200$Domestic_m, decreasing = T),]
agh[24, ]
agh <- top200[order(top200$Domestic_m, decreasing = T),]
agh[24, ]
View(top200)
top20 <- head(top200, 25)
View(top20)
top20 <- head(top200, 20)
install.packages(car)
library(car)
library(car)
install.packages(car)
library(car)
data(Prestige)
help(Prestige)
install.packages(car)
install.packages(car)
install.packages(car)
library(car)
data(Prestige)
help(Prestige)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
summary(cars)
cars
install.packages(cars)
library(cars)
install.packages(Cars)
install.packages("car")
library("car")
data(Prestige)
help(Prestige)
View(Prestige)
str(Prestige)
# a)
# Prestige$professional <- factor(NA, levels = c("")
Prestige$professional <- Prestige$type[Prestige$type == "prof"] <- 1
setwd("/Users/jasminlim/Documents/GitHub/QTM200Spring2020/problem_sets/PS4/template")
# Installing required packages
install.packages("car")
install.packages("car")
library("car")
data(Prestige)
help(Prestige)
View(Prestige)
Prestige$professional <- Prestige$type[Prestige$type == "prof"] <- 1
data(Prestige)
# a)
Prestige$professional <- Prestige[Prestige$type == "prof"] <- 1
# a)
Prestige$professional
# a)
Prestige$professional <- factor(NA, levels = c("0", "1"))
# a)
Prestige$professional[Prestige$type == "prof"] <- 1
Prestige$professional[Prestige$type[Prestige$type == "bc"] <- 0
# a)
Prestige$professional[Prestige$type == "prof"] <- 1
Prestige$professional[Prestige$type[Prestige$type == "bc"] <- 0
Prestige$professional[Prestige$type == "bc"] <- 0
Prestige$professional[Prestige$type ==  "wc"] <- 0
Prestige$professional[Prestige$type == "bc"] <- 0
# Installing required packages
install.packages("car")
install.packages("car")
library("car")
data(Prestige)
help(Prestige)
# a)
Prestige$professional[Prestige$type == "prof"] <- 1
Prestige$professional[Prestige$type == "bc"] <- 0
Prestige$professional[Prestige$type ==  "wc"] <- 0
?ifelse
# a)
ifelse(Prestige$type == "prof", 0, 1)
data(Prestige)
View(Prestige)
# a)
ifelse(Prestige$type == "prof", 0, 1)
# a)
Prestige$professional <- ifelse(Prestige$type == "prof", 0, 1)
# a)
Prestige$professional <- ifelse(Prestige$type == "prof", 1, 0)
# Run a linear model with prestige as an outcome and income, professional, and the
# interaction of the two as predictors (Note: this is a continuous dummy interaction.)
lm1 <- lm(prestige ~ income + professional, data = Prestige)
summary(lm1)
lm1
# Linear model with prestige as outcome and income, professional, and the interaction of the two as predictors
lm1 <- lm(prestige ~ income + professional + income:professional, data = Prestige)
summary(lm1)
# Interpret coefficient for income
0.0032 - 0.0023
# Linear model with prestige as outcome and income, professional, and the interaction of the two as predictors
lm1 <- lm(prestige ~ income + professional + income:professional, data = Prestige)
summary(lm1)
# Linear model with prestige as outcome and income, professional, and the interaction of the two as predictors
lm1 <- lm(prestige ~ income + professional + income:professional, data = Prestige)
summary(lm1)
