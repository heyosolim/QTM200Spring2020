gss <- read.csv("gss.csv")
gss$marital
is.na(gss$marital)
gss <- read.csv("gss.csv")
sum(is.na(gss$marital))
(gss$sex == "FEMALE") /  gss$sex
gss$sex <- na.omit(gss$sex)
gss$sex <- na.omit(gss$sex)
(gss$sex == "FEMALE") /  gss$sex
gss$clean <- na.omit(gss$sex)
summary(gss$clean)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
gss <- read.csv("gss.csv")
sum(is.na(gss$marital)) # 20 missing values
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
gss$clean_sex
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
summary(gss$clean_sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE")
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / sum(gss$clean_sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / sum(gss$clean_sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / sum(gss$clean_sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE")
sum(gss$clean_sex)
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE")
?sum
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / sum(gss$clean_sex, na.rm = T)
knitr::opts_chunk$set(echo = TRUE)
schoolyear<-c("Freshman","Sophomore","Junior","Senior")
schoolyear
x<-c(2,4, 3,1)
# give the names to the numeric vector with the character vector
names(x)<-schoolyear
x
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / (sum(gss$clean_sex == "MALE") + sum(gss$clean_sex == "FEMALE"))
?sum
btwn_30_40 <- sum(gss$age >= 30 && gss$age <= 40, na.rm = T)
btwn_30_40 <- sum(gss$age >= 30 && gss$age <= 40, na.rm = T)
btwn_30_40
btwn_30_40 <- sum(gss$age >= 30, na.rm = T)
btwn_30_40
btwn_30_40 <- sum(gss$age >= 30 && gss$age <= 40, na.rm = T)
btwn_30_40
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40 / count(gss, )
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
#btwn_30_40 / count(gss, )
?count
#btwn_30_40 / count(gss, )
?dim
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
#btwn_30_40 / count(gss, )
dim(gss$age)
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
#btwn_30_40 / count(gss, )
dim(gss)
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
#btwn_30_40 / count(gss, )
dim(gss, na.rm = T)
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
#btwn_30_40 / count(gss, )
dim(gss)
# 56.14 % of female
?length
summary(gss$sex)
gss$clean_sex <- na.omit(gss$sex)
sum(gss$clean_sex == "FEMALE") / length(gss$clean_sex)
# 56.14 % of female
summary(gss$sex)
sum(gss$sex == "FEMALE") / length(na.omit(gss$sex))
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40 / length(na.omit(gss$age))
?subset
avg_age <- subset(gss, year == 2009 || year == 2010)
avg_age <- subset(gss, year == 2009 || year == 2010, na.rm = T)
avg_age <- subset(gss, year == 2009 || year == 2010)
mean(avg_age$age, na.rm = T)
View(avg_age)
avg_age <- subset(gss, year == 2009 | year == 2010)
mean(avg_age$age, na.rm = T)
4.
```{r}
avg_age <- subset(gss, year == 2009 | year == 2010)
mean(avg_age$age, na.rm = T)
# Average age of respondents who took the survey in 2009/2010 is about 48
```
weekdays <- factor()
?factor
y<-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y, ordered = T, levels = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
y<-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y, ordered = T, levels = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
y<-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y, ordered = T, levels = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
y <-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y, levels = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
y <-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y)
summary(weekdays)
weekdays <- factor(y, levels = c("Thurs", "Fri", "Sat", "Sun"))
y <-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y, levels = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
y <-c(1,2,1,3,4,1,1,4,2,1,3,4,3,2,1,3,4,1,2,3,1,1,2)
weekdays <- factor(y)
levels(weekdays) = c("Thurs", "Fri", "Sat", "Sun"))
summary(weekdays)
levels(weekdays) = c("Thurs", "Fri", "Sat", "Sun")
summary(weekdays)
?sum
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40)
btwn_30_40 / length(na.omit(gss$age))
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40 <- sum(gss$age >= 30 & gss$age <= 40, na.rm = T)
btwn_30_40 / length(na.omit(gss$age))
knitr::opts_chunk$set(echo = TRUE)
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
dim(gss) #This dataset contains 53474 rows and 14 variables
set.seed(1234) #generating a random number sequence
?set.seed
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
# save dataset and rmd files are in the same folder
gss<-read.csv("gss.csv")  # import dataset in R
dim(gss) #This dataset contains 53474 rows and 14 variables
dim(gss) #This dataset contains 53474 rows and 14 variables
set.seed(1234) #generating a random number sequence
set.seed(1234) #generating a random number sequence
gss100<-gss[sample(nrow(gss),100),] #store 100 observations into an object called gss100
dim(gss100)
dim(gss) #This dataset contains 53474 rows and 14 variables
names(gss100) #get variable names
dim(gss100) # the number of observations and variables
summary(gss100)
head(gss100)  # print the first six observations
sum(is.na(gss$age)) #print a total number of missing values of age in the original dataset
sum(is.na(gss100$age)) #print a total number of missing values of age in the smaller dataset we created
#dataset[row, column]
gss100[1,2]
head(gss100)  # print the first six observations
#dataset[row, column]
gss100[1,2]
# dataset[rows, columns]
gss100[1:5, c(2,5)]
#dataset$variable, the whole column
gss100[,7]
gss100$marital
# dataset$variable[rows]
gss100$marital[1:10]
# one quantitative variable:
hist(gss100$age)
mean(gss100$age)
sd(gss100$age)
# one categorical variable:
# barplot(frequency table)
table(gss100$marital)
barplot(table(gss100$marital))
# one quantitative vs one categorical
boxplot(gss100$age~gss100$sex)
# str() can tell us
str(gss100)
c(1,2,3)
# We can save this to a named object:
x<-c(1:10)  # The : sybmbol used to create a sequence of increasing (or decreasing) values
x
y<-c(30:1)
y
# use the square bracket to extract the element(value)
x[5]
x[c(1,3,5)]
x[3:7]
x[-c(1,3,5,7,9)]
# seq(start, end, by=1)
seq(0,100,by=5) # the sequence of numbers from 0 to 100 with the increment is 5
# rep(x, times of repetition)
rep(2,5)    # repeat the value 2, 5 times
x<-c(1:5)
rep(x,2)  # repeat x twice
y<-c(10:15)
rep(c(x,y),2)  # repeat x and y, twice
set.seed(1234)
sample(1:10, 5, replace=TRUE)
7 %% 2  # the modular operator, the remainder of the division of 7 by 2.
7 %/% 2
x %% 2 # odd number and even number
y<-c(6:10)
x+y  # the same length
y-x
x
sum(x)
mean(x)
length(x)
avg_x<-sum(x)/length(x)
avg_x
a<-c(1, 5, 6, 8, 9, 15, 20, 19, 10)
sum(a%%2)
# check odd numbers:
a%%2
# check odd numbers:
sum(a%%2)
schoolyear<-c("Freshman","Sophomore","Junior","Senior")
schoolyear
x<-c(2,4, 3,1)
# give the names to the numeric vector with the character vector
names(x)<-schoolyear
x
substr(schoolyear,1,2)
scoolyear1<-paste(schoolyear,"Year")
paste("The",schoolyear,"Year", sep=" ")
tolower(schoolyear)
substr(schoolyear,1,2)
scoolyear1<-paste(schoolyear,"Year")
schoolyear1
schoolyear
scoolyear1
paste("The",schoolyear,"Year", sep=" ")
scoolyear1
paste("The",schoolyear,"Year", sep=" ")
tolower(schoolyear)
tolower(schoolyear)
substr(state.name, 1, 1)
# translate all the state names to lower case
tolower(state.name)
x<-c(1:5)
x>3
3==4
schoolyear %in% "Senior"
"Senior" %in% schoolyear
sum(x>3)
gss100subset<-gss100[gss100$year==2010,]
head(gss100subset)
state.name[substr(state.name,1,1)=="N"]
schoolyear[substr(schoolyear,1,1)=="S"]
gss <- read.csv("gss.csv")
set.seed(1111)
sample1001 <- sample(gss, 1001)
sample1001 <- sample(gss, 1001, replace = T)
sample1001
dim(sample1001)
gss[sample(nrow(gss),1001]
gss[sample(nrow(gss),1001),]
dim(sampleZ)
sample2 <- gss[sample(nrow(gss),1001),]
dim(sampleZ)
dim(sample2)
View(sample1001)
gss1001[c(1:15), c("income","happy","age","degree","polviews","sex")]
sample2[c(1:15), c("income","happy","age","degree","polviews","sex")]
sum(is.na(gss101$income))
sum(is.na(sample2$income))
gss <- read.csv("gss.csv")
set.seed(1111)
gss1001 <- gss[sample(nrow(gss),1001),]
dim(gss1001)
gss1001[c(1:15), c("income","happy","age","degree","polviews","sex")]
sum(is.na(gss1001$income))
gss1001_NAincome <- gss1001[is.na(gss1001$Income), ]
View(gss1001_NAincome)
View(gss)
gss1001_NAincome <- gss1001[is.na(gss1001$income), ]
View(gss1001_NAincome)
mean(gss1001$age[gss1001$sex=="MALE"])
View(gss)
gss1001_seniors <- subset(gss1001, age >= 65)
View(gss1001_seniors)
gss1001_veryhappy <- gss1001[gss1001$happy=="VERY HAPPY", ]
View(gss1001_veryhappy)
gss1001_veryhappy <- gss1001[gss1001$happy=="VERY HAPPY" & !is.na(gss1001$happy), ]
View(gss1001_veryhappy)
gss1001 <- gss(sample(nrow(gss),1001,)
gss1001
gss1001[c(1:15), c("income","happy","age","degree","polviews","sex")]
sum(is.na(gss1001$income))
gss1001_NAincome <- gss1001[is.na(gss1001$income), ]
View(gss1001_NAincome)
mean(gss1001$age[gss1001$sex=="MALE"])
mean(gss1001$age[gss1001$sex=="MALE"], na.rm = T)
mean(gss1001$age[gss1001$sex%in%"MALE"], na.rm = T)
gss1001_seniors <- subset(gss1001, age >= 65)
View(gss1001_seniors)
gss1001_veryhappy <- gss1001[gss1001$happy=="VERY HAPPY" & !is.na(gss1001$happy), ]
View(gss1001_veryhappy)
z95 <- qnorm((1 - 0.95) / 2, lower.tail = F)
z95 <- qnorm((1 - 0.95) / 2, lower.tail = T)
z95 <- qnorm((1 - 0.95) / 2, lower.tail = F)
pnorm(-abs(z95))
pnorm(abs(z95))
?pnorm
pnorm(abs(z95), lower.tail = F) # lower tail by defauly
2 * pt (2.279, df = 49, lower.tail = F)
2 * pt(-2.279, df = 49)
pnorm(23.57)
pnorm(-23.57)
pnorm(-23.57, lower.tail = F)
pnorm(-23.57, lower.tail = F)
qnorm(.025, lower.tail = F)
75/6
qnorm(.025, lower.tail = F) * 75/6
(qnorm(.025, lower.tail = F)) * 75/6
pnorm(-23.57, lower.tail = F)
pnorm(23.57, lower.tail = T)
pnorm(-23.57, lower.tail = F)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
mean <- mean(y)
size <- length(y)
size
sd <- sd(y)
se <- sd / sqrt(size)
z90 <- ( ( 1- 0.9) / 2, lower.tail = F)
t90 <- qt((1- 0.9) / 2, df = 24, lower.tail = F)
mean + t90 * se
mean - t90 * se
ts <- (mean - 100 ) / se
pt(ts, df = 24, lower.tail = F)
t.test(y, mu = 100, conf.level = 0.95, alternative = "greater")
(217-225)/ (40/ 10)
pt(-2, df = 99)
pt(-2, df = 99) * 2
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c("faraway"),  pkgTest)
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS5")
# load data
gamble <- (data=teengamb)
# run regression on gamble with specified predictors
model1 <- lm(gamble ~ sex + status + income + verbal, gamble)
plot(model1$fitted, model1$residuals)
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(model1)
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(rstandard(model1))
qqline(rstandard(model1))
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(studres(model1))
library(car)
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(studres(model1))
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
ugh <- studres(model1)
qqnorm(rstudent(model1))
qqline(rstudent(model1))
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(rstudent(model1))
qqline(rstudent(model1))
plot(model1$fitted, model1$residuals)
abline(h=0,lty=2)
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
plot(model1)
plot(model1$fitted, model1$residuals)
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
plot(model1)
# the fitted values.
plot(model1)
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(rstudent(model1))
qqline(rstudent(model1))
plot(model1$fitted, model1$residuals)
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
plot(model1)
qqline(rstudent(model1))
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
qqnorm(rstudent(model1))
# (c) Check for large leverage points by plotting the h values.
plot (hatvalues(model1) , pch =16 , cex =2)
# (c) Check for large leverage points by plotting the h values.
plot(hatvalues(model1))
abline(h = 2 * 5 / 47)
abline(h = 2 * 5 / 47)
abline(h = 3 * 5 / 47)
# (d) Check for outliers by running an outlierTest.
outliertest(model1)
# (d) Check for outliers by running an outlierTest.
outlierTest(model1)
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
plot(hatvalues(model1), rstudent(model1), type = "n")
length(gamble)
View(gamble)
plot(hatvalues(model1), rstudent(model1), type = "n")
cook <- sqrt(cooks.distance(model1))
points(hatvalues(model1), rstudent(model1), cex = 10 * cook / max(cook))
abline(h = c(-2, 0, 2) , lty = 2)
abline(v = c(2, 3) * 3/ 45, lty = 2)
abline(v = c(2, 3) * 3/ 45, lty = 2)
identify(hatvalues(model1), rstudent(model1), row.names(gamble))
identify(hatvalues(model1), rstudent(model1), row.names(gamble))
plot(hatvalues(model1), rstudent(model1), type = "n")
cook <- sqrt(cooks.distance(model1))
points(hatvalues(model1), rstudent(model1), cex = 10 * cook / max(cook))
abline(h = c(-2, 0, 2) , lty = 2)
abline(v = c(2, 3) * 3/ 45, lty = 2)
identify(hatvalues(model1), rstudent(model1), row.names(gamble))
abline(v = c(2, 3) * 3/ 47, lty = 2)
abline(v = c(2, 3) * 3/ 47, lty = 2)
abline(v = c(2, 3) * 3/ 45, lty = 2)
abline(v = c(2, 3) * 5/ 47, lty = 2)
plot(hatvalues(model1), rstudent(model1), type = "n")
cook <- sqrt(cooks.distance(model1))
points(hatvalues(model1), rstudent(model1), cex = 10 * cook / max(cook))
abline(h = c(-2, 0, 2), lty = 2)
identify(hatvalues(model1), rstudent(model1), row.names(gamble))
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
plot(hatvalues(model1), rstudent(model1), type = "n")
cook <- sqrt(cooks.distance(model1))
points(hatvalues(model1), rstudent(model1), cex = 10 * cook / max(cook))
abline(h = c(-2, 0, 2), lty = 2)
abline(v = c(2, 3) * 5 / 47, lty = 2)
abline(h = c(-2, 0, 2), lty = 2)
abline(v = c(2, 3) * 5 / 47, lty = 2)
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
pdf("plot1.pdf")
plot(model1)
abline(h=0,lty=2)
dev.off()
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
pdf("plot1.pdf")
plot(model1)
abline(h=0,lty=2)
dev.off()
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS5/template")
# (a) Check the constant variance assumption for the errors by plotting the residuals versus
# the fitted values.
pdf("plot1.pdf")
plot(model1)
abline(h=0,lty=2)
dev.off()
# (b) Check the normality assumption with a Q-Q plot of the studentized residuals.
pdf("plot2.pdf")
qqnorm(rstudent(model1))
qqline(rstudent(model1))
dev.off()
# (c) Check for large leverage points by plotting the h values.
pdf("plot3.pdf")
plot(hatvalues(model1))
abline(h = 2 * 5 / 47) # Based on the thresholds and k (number of predictors) = 4
abline(h = 3 * 5 / 47)
dev.off()
pdf("plot4.pdf")
plot(hatvalues(model1), rstudent(model1), type = "n")
cook <- sqrt(cooks.distance(model1))
points(hatvalues(model1), rstudent(model1), cex = 10 * cook / max(cook))
abline(h = c(-2, 0, 2), lty = 2)
abline(v = c(2, 3) * 5 / 47, lty = 2)
identify(hatvalues(model1), rstudent(model1), row.names(gamble))
dev.off()
# (d) Check for outliers by running an outlierTest.
outlierTest(model1, row.names(gamble))
