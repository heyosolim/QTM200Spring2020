cor.test(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew) # Weak, positive correlation
m1 <- lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew)
summary(m1) # Regression results
confint(m1) # Confidence intervals for constant and slope
hist(rstandard(m1)) # Histogram of standardized residuals is right-skewed
qqnorm(rstandard(m1)) # Produces qq plot
qqline(rstandard(m1)) # Adds line to qq plot; points do not lie on the line
plot(predict(m1),rstandard(m1),xlab ="Fitted Values",ylab ="Standardized Residuals")
abline(h = 0,lty = 2) # Adds line at y = 0
# Random scatter around about the line, so assumptions regarding linear relationship and constant
# variance are satisfied overall.
################## Tables for Appendix A ##################
# Filling out Table 1
# Stats for Age vs. Loss of Productivity
addmargins(table(NTDB_Splenic$LOSDAYSD))
summarySE(data = NTDB_Splenic, measurevar = "AGENew", na.rm = T)
summarySE(data = NTDB_Splenic,  groupvar = "LOSDAYSD", measurevar = "AGENew", na.rm = T)
# Stats for Age vs. Gender
gender.par.tab <- table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
gender.par.tab
addmargins(gender.par.tab)
prop.table(gender.par.tab, margin = 1)
# Stats for Gender
table(NTDB_Splenic$GENDERNew)
prop.table(table(NTDB_Splenic$GENDERNew))
# Stats for Procedure vs. Loss of Productivity
procedure.par.tab <- table(NTDB_Splenic$Group1New, NTDB_Splenic$LOSDAYSD)
procedure.par.tab
addmargins(procedure.par.tab)
prop.table(procedure.par.tab, margin = 1)
# Stats for Procedure
table(NTDB_Splenic$Group1New)
prop.table(table(NTDB_Splenic$Group1New))
# Table 2 consists of counts/marginal proportions from Table 1 and results of chi-squared test
# Filling out Table 3
summarySE(data = NTDB_Splenic, groupvars = "GENDERNew", measurevar = "LOSDAYSNew", na.rm = T)
addmargins(table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSNew)) # Gives total number of observations
# Table 4 consists of results of linear model/regression and the confidence intervals
# Degrees of freedom = N - 2 since the model is estimating two parameters (the slope and constant)
################## Plots for Appendix B ##################
# Plot for Research Question 1
NTDB_Splenic$Group1New <- factor(NTDB_Splenic$Group1New, c("Non_Operative", "Angiography", "Embolization", "Splenic_Repair", "Splenectomy", "Combination"))
procedure.par.tab <- table(NTDB_Splenic$LOSDAYSD, NTDB_Splenic$Group1New)
barplot(prop.table(procedure.par.tab, margin = 2), beside = T, legend.text = T, xlab = "Types of Procedure", ylab = "Marginal Proportion", cex.names = 0.65)
# Plotting for Research Question 2
boxplot(NTDB_Splenic$LOSDAYSNew ~ NTDB_Splenic$GENDERNew, xlab= "Patient's Gender", ylab="Length of Hospital Stay (days)" )
# Plot for Research Question 3
plot(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew, xlab="Patient's Age ", ylab="Stay in Days ")
abline(lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew), col="red")
## Jasmin Lim
## 12/8/19
## QTM 100 Section 7
## Final Project Submission
## Title: Loss of Productivity Following Splenic Procedures
# Importing dataset
NTDB_Splenic <- read.csv("/Users/jasminlim/Documents/Emory Stuff/Fall 2019/QTM 100/Lab/Dataset/NTDB_Splenic.csv")
library("Rmisc")
################## Recoding and Cleaning ##################
# Recoding Variable 1: Total length of hospital stay
NTDB_Splenic$LOSDAYSNew <- NTDB_Splenic$LOSDAYS
summary(NTDB_Splenic$LOSDAYS)
# IQR = 10 - 3 = 7
# IQR * 1.5 = 10.5
# 10 + 10.5 = 20.5; upper limit for non-outliers
NTDB_Splenic$LOSDAYSNew[NTDB_Splenic$LOSDAYS < 0] <- NA # Negative values as NA
NTDB_Splenic$LOSDAYSNew[NTDB_Splenic$LOSDAYS > 20.5] <- NA # Outliers as NA
summary(NTDB_Splenic$LOSDAYSNew) # Checking Recoding
# Dichotomization of Variable 1
NTDB_Splenic$LOSDAYSD <- factor(NA, levels=c("No sig. loss of productivity", "Sig. loss of productivity"))
NTDB_Splenic$LOSDAYSD[NTDB_Splenic$LOSDAYSNew <= 7] <-"No sig. loss of productivity"
NTDB_Splenic$LOSDAYSD[NTDB_Splenic$LOSDAYSNew > 7] <-"Sig. loss of productivity"
# Recoding Variable 2: Hospital Procedures
summary(NTDB_Splenic$Group1) # Two extra categories not properly capitalized
NTDB_Splenic$Group1New <- NTDB_Splenic$Group1
NTDB_Splenic$Group1New[NTDB_Splenic$Group1=="non_operative"] <- "Non_Operative"
NTDB_Splenic$Group1New[NTDB_Splenic$Group1=="splenectomy"] <- "Splenectomy"
summary(NTDB_Splenic$Group1New) # Checking recoding
NTDB_Splenic$Group1New <- factor(NTDB_Splenic$Group1New) # Removing incorrect factor levels
# Recoding Variable 3: Age of Patients
summary(NTDB_Splenic$AGE)
NTDB_Splenic$AGENew <- NTDB_Splenic$AGE
NTDB_Splenic$AGENew[NTDB_Splenic$AGE<18] <- NA # observations less than 18 will be considered to be in the children demographic and therefore will not be accounted in this study
NTDB_Splenic$AGENew[NTDB_Splenic$AGE>= 62] <- NA # observations greater or equal to 62 will be considered to be retired and therefore will not be accounted in this study
summary(NTDB_Splenic$AGENew) # Checking recoding
# Recoding Variable 4: Gender of Patients
NTDB_Splenic$GENDERNew<-NTDB_Splenic$GENDER # Negative values as gender categories
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-1"]<- NA
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-2"]<- NA
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-3"]<- NA
NTDB_Splenic$GENDERNew <- factor(NTDB_Splenic$GENDERNew) # Removing incorrect factor levels
table(NTDB_Splenic$GENDERNew) # Checking recoding
################## Statistical Tests ##################
# Chi-squared test for Research Question 1
# Asumptions met: Observations are randomly sampled and independent from one another
procedure.par.tab <- table(NTDB_Splenic$Group1New, NTDB_Splenic$LOSDAYSD)
addmargins(procedure.par.tab)
prop.table(procedure.par.tab, margin = 1)
chisq.test(procedure.par.tab,correct = F)
proced.prod.test <- chisq.test(procedure.par.tab,correct = F)
proced.prod.test$expected # Expected cell counts > 5; assumption for expected cell counts satisfied
# Two-sample t-test for Research Question 2
summarySE(data = NTDB_Splenic, groupvars = "GENDERNew", measurevar = "LOSDAYSNew", na.rm = T)
# Standard deviations are very similar, so will assume equal variance
# Asumptions met: Observations are randomly sampled and independent from one another
# Large sample sizes in both male and female (n > 30), so normality assumption is satisfied
t.test(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$GENDERNew,var.equal=TRUE)
# Linear Regression for Research Question 3
hist(NTDB_Splenic$LOSDAYSNew) # Histogram of responding variable is right-skewed
cor.test(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew) # Weak, positive correlation
m1 <- lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew)
summary(m1) # Regression results
confint(m1) # Confidence intervals for constant and slope
hist(rstandard(m1)) # Histogram of standardized residuals is right-skewed
qqnorm(rstandard(m1)) # Produces qq plot
qqline(rstandard(m1)) # Adds line to qq plot; points do not lie on the line
plot(predict(m1),rstandard(m1),xlab ="Fitted Values",ylab ="Standardized Residuals")
abline(h = 0,lty = 2) # Adds line at y = 0
# Random scatter around about the line, so assumptions regarding linear relationship and constant
# variance are satisfied overall.
################## Tables for Appendix A ##################
# Filling out Table 1
# Stats for Age vs. Loss of Productivity
addmargins(table(NTDB_Splenic$LOSDAYSD))
summarySE(data = NTDB_Splenic, measurevar = "AGENew", na.rm = T)
summarySE(data = NTDB_Splenic,  groupvar = "LOSDAYSD", measurevar = "AGENew", na.rm = T)
# Stats for Age vs. Gender
gender.par.tab <- table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
gender.par.tab
addmargins(gender.par.tab)
prop.table(gender.par.tab, margin = 1)
# Stats for Gender
table(NTDB_Splenic$GENDERNew)
prop.table(table(NTDB_Splenic$GENDERNew))
# Stats for Procedure vs. Loss of Productivity
procedure.par.tab <- table(NTDB_Splenic$Group1New, NTDB_Splenic$LOSDAYSD)
procedure.par.tab
addmargins(procedure.par.tab)
prop.table(procedure.par.tab, margin = 1)
# Stats for Procedure
table(NTDB_Splenic$Group1New)
prop.table(table(NTDB_Splenic$Group1New))
# Table 2 consists of counts/marginal proportions from Table 1 and results of chi-squared test
# Filling out Table 3
summarySE(data = NTDB_Splenic, groupvars = "GENDERNew", measurevar = "LOSDAYSNew", na.rm = T)
addmargins(table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSNew)) # Gives total number of observations
# Table 4 consists of results of linear model/regression and the confidence intervals
# Degrees of freedom = N - 2 since the model is estimating two parameters (the slope and constant)
################## Plots for Appendix B ##################
# Plot for Research Question 1
NTDB_Splenic$Group1New <- factor(NTDB_Splenic$Group1New, c("Non_Operative", "Angiography", "Embolization", "Splenic_Repair", "Splenectomy", "Combination"))
procedure.par.tab <- table(NTDB_Splenic$LOSDAYSD, NTDB_Splenic$Group1New)
barplot(prop.table(procedure.par.tab, margin = 2), beside = T, legend.text = T, xlab = "Types of Procedure", ylab = "Marginal Proportion", cex.names = 0.65)
# Plotting for Research Question 2
boxplot(NTDB_Splenic$LOSDAYSNew ~ NTDB_Splenic$GENDERNew, xlab= "Patient's Gender", ylab="Length of Hospital Stay (days)" )
# Plot for Research Question 3
plot(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew, xlab="Patient's Age ", ylab="Stay in Days ")
abline(lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew), col="red")
summary(m1) # Regression results
cor.test(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew) # Weak, positive correlation
m1 <- lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew)
summary(m1) # Regression results
summary(m1) # Regression results
cor.test(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew) # Weak, positive correlation
m1 <- lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew)
summary(m1) # Regression results
# Standard deviations are very similar, so will assume equal variance
# Asumptions met: Observations are randomly sampled and independent from one another
# Large sample sizes in both male and female (n > 30), so normality assumption is satisfied
t.test(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$GENDERNew,var.equal=TRUE)
# Importing dataset
NTDB_Splenic <- read.csv("/Users/jasminlim/Documents/Emory Stuff/Fall 2019/QTM 100/Lab/Dataset/NTDB_Splenic.csv")
library("Rmisc")
# Recoding Variable 1: Total length of hospital stay
NTDB_Splenic$LOSDAYSNew <- NTDB_Splenic$LOSDAYS
summary(NTDB_Splenic$LOSDAYS)
# IQR = 10 - 3 = 7
# IQR * 1.5 = 10.5
# 10 + 10.5 = 20.5; upper limit for non-outliers
NTDB_Splenic$LOSDAYSNew[NTDB_Splenic$LOSDAYS < 0] <- NA # Negative values as NA
NTDB_Splenic$LOSDAYSNew[NTDB_Splenic$LOSDAYS > 20.5] <- NA # Outliers as NA
summary(NTDB_Splenic$LOSDAYSNew) # Checking Recoding
# Dichotomization of Variable 1
NTDB_Splenic$LOSDAYSD <- factor(NA, levels=c("No sig. loss of productivity", "Sig. loss of productivity"))
NTDB_Splenic$LOSDAYSD[NTDB_Splenic$LOSDAYSNew <= 7] <-"No sig. loss of productivity"
NTDB_Splenic$LOSDAYSD[NTDB_Splenic$LOSDAYSNew > 7] <-"Sig. loss of productivity"
# Recoding Variable 2: Hospital Procedures
summary(NTDB_Splenic$Group1) # Two extra categories not properly capitalized
NTDB_Splenic$Group1New <- NTDB_Splenic$Group1
NTDB_Splenic$Group1New[NTDB_Splenic$Group1=="non_operative"] <- "Non_Operative"
NTDB_Splenic$Group1New[NTDB_Splenic$Group1=="splenectomy"] <- "Splenectomy"
summary(NTDB_Splenic$Group1New) # Checking recoding
NTDB_Splenic$Group1New <- factor(NTDB_Splenic$Group1New) # Removing incorrect factor levels
# Recoding Variable 3: Age of Patients
summary(NTDB_Splenic$AGE)
NTDB_Splenic$AGENew <- NTDB_Splenic$AGE
NTDB_Splenic$AGENew[NTDB_Splenic$AGE<18] <- NA # observations less than 18 will be considered to be in the children demographic and therefore will not be accounted in this study
NTDB_Splenic$AGENew[NTDB_Splenic$AGE>= 62] <- NA # observations greater or equal to 62 will be considered to be retired and therefore will not be accounted in this study
summary(NTDB_Splenic$AGENew) # Checking recoding
# Recoding Variable 4: Gender of Patients
NTDB_Splenic$GENDERNew<-NTDB_Splenic$GENDER # Negative values as gender categories
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-1"]<- NA
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-2"]<- NA
NTDB_Splenic$GENDERNew[NTDB_Splenic$GENDER=="-3"]<- NA
NTDB_Splenic$GENDERNew <- factor(NTDB_Splenic$GENDERNew) # Removing incorrect factor levels
table(NTDB_Splenic$GENDERNew) # Checking recoding
# Chi-squared test for Research Question 1
# Asumptions met: Observations are randomly sampled and independent from one another
procedure.par.tab <- table(NTDB_Splenic$Group1New, NTDB_Splenic$LOSDAYSD)
addmargins(procedure.par.tab)
prop.table(procedure.par.tab, margin = 1)
chisq.test(procedure.par.tab,correct = F)
proced.prod.test <- chisq.test(procedure.par.tab,correct = F)
proced.prod.test$expected # Expected cell counts > 5; assumption for expected cell counts satisfied
# Two-sample t-test for Research Question 2
summarySE(data = NTDB_Splenic, groupvars = "GENDERNew", measurevar = "LOSDAYSNew", na.rm = T)
# Standard deviations are very similar, so will assume equal variance
# Asumptions met: Observations are randomly sampled and independent from one another
# Large sample sizes in both male and female (n > 30), so normality assumption is satisfied
t.test(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$GENDERNew,var.equal=TRUE)
# Linear Regression for Research Question 3
hist(NTDB_Splenic$LOSDAYSNew) # Histogram of responding variable is right-skewed
cor.test(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew) # Weak, positive correlation
m1 <- lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew)
summary(m1) # Regression results
confint(m1) # Confidence intervals for constant and slope
hist(rstandard(m1)) # Histogram of standardized residuals is right-skewed (ok because line 83)
qqnorm(rstandard(m1)) # Produces qq plot
qqline(rstandard(m1)) # Adds line to qq plot; points do not lie on the line
plot(predict(m1),rstandard(m1),xlab ="Fitted Values",ylab ="Standardized Residuals")
abline(h = 0,lty = 2) # Adds line at y = 0
# Stats for Age vs. Loss of Productivity
addmargins(table(NTDB_Splenic$LOSDAYSD))
summarySE(data = NTDB_Splenic, measurevar = "AGENew", na.rm = T)
summarySE(data = NTDB_Splenic,  groupvar = "LOSDAYSD", measurevar = "AGENew", na.rm = T)
# Stats for Age vs. Gender
gender.par.tab <- table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
gender.par.tab
addmargins(gender.par.tab)
prop.table(gender.par.tab, margin = 1)
# Stats for Gender
table(NTDB_Splenic$GENDERNew)
prop.table(table(NTDB_Splenic$GENDERNew))
# Stats for Procedure vs. Loss of Productivity
procedure.par.tab <- table(NTDB_Splenic$Group1New, NTDB_Splenic$LOSDAYSD)
procedure.par.tab
addmargins(procedure.par.tab)
prop.table(procedure.par.tab, margin = 1)
# Stats for Procedure
table(NTDB_Splenic$Group1New)
prop.table(table(NTDB_Splenic$Group1New))
# Filling out Table 3
summarySE(data = NTDB_Splenic, groupvars = "GENDERNew", measurevar = "LOSDAYSNew", na.rm = T)
addmargins(table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSNew)) # Gives total number of observations
# Plot for Research Question 1: Loss of Productivity vs. Types of Procedure
NTDB_Splenic$Group1New <- factor(NTDB_Splenic$Group1New, c("Non_Operative", "Angiography", "Embolization", "Splenic_Repair", "Splenectomy", "Combination"))
procedure.par.tab <- table(NTDB_Splenic$LOSDAYSD, NTDB_Splenic$Group1New)
barplot(prop.table(procedure.par.tab, margin = 2), beside = T, legend.text = T, xlab = "Types of Procedure", ylab = "Marginal Proportion", cex.names = 0.65)
# Plotting for Research Question 2: Length of Hospital Stay vs. Gender
boxplot(NTDB_Splenic$LOSDAYSNew ~ NTDB_Splenic$GENDERNew, xlab= "Patient's Gender", ylab="Length of Hospital Stay (days)" )
# Plot for Research Question 3: Length of Hospital Stay vs. Age
plot(NTDB_Splenic$AGENew, NTDB_Splenic$LOSDAYSNew, xlab="Patient's Age ", ylab="Stay in Days ")
abline(lm(NTDB_Splenic$LOSDAYSNew~NTDB_Splenic$AGENew), col="red")
# Stats for Age vs. Gender
gender.par.tab <- table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
gender.par.tab
addmargins(gender.par.tab)
prop.table(gender.par.tab, margin = 1)
# Stats for Gender vs. Loss of Productivity
gender.par.tab <- table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
gender.par.tab
addmargins(gender.par.tab)
# Stats for Gender vs. Loss of Productivity
table(NTDB_Splenic$GENDERNew, NTDB_Splenic$LOSDAYSD)
getwd()
5 + 2
26 %/% 4
26 %% 4
5 + 2
26 / 4
26 %/% 4
26 %% 4
t.test(y, mu = 100) # Conducting one sample t-test
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t.test(y, mu = 100) # Conducting one sample t-test
confint <- c(lower_90, upper_90)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qt((1 - 0.9) / 2, lower.tail = FALSE, df = 24) # z-score for 90% confidence interval with 24 degrees of freedom
n <- length(y) # sample size
sample_mean <- mean(y) # sample mean
sample_sd <- sd(y) # sample standard deviation
sample_se <- sample_sd / sqrt(n) # standard error
lower_90 <- sample_mean - (z90 * sample_se) # lower bound of 90% confidence interval
upper_90 <- sample_mean + (z90 * sample_se) # upper bound of 90% confidence interval
confint <- c(lower_90, upper_90)
confint # 90% confidence interval
t.test(y, mu = 100) # Conducting one sample t-test
?t.test
t.test(y, mu = 100, conf.level = 0.9 )
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t90 <- qt((1 - 0.9) / 2, lower.tail = FALSE, df = 24) # z-score for 90% confidence interval with 24 degrees of freedom
n <- length(y) # sample size
sample_mean <- mean(y) # sample mean
sample_sd <- sd(y) # sample standard deviation
sample_se <- sample_sd / sqrt(n) # standard error
lower_90 <- sample_mean - (t90 * sample_se) # lower bound of 90% confidence interval
upper_90 <- sample_mean + (t90 * sample_se) # upper bound of 90% confidence interval
confint <- c(lower_90, upper_90)
confint # 90% confidence interval
confint # 90% confidence interval
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t90 <- qt((1 - 0.9) / 2, lower.tail = FALSE, df = 24) # t-score for 90% confidence interval with 24 degrees of freedom
n <- length(y) # sample size
sample_mean <- mean(y) # sample mean
sample_sd <- sd(y) # sample standard deviation
sample_se <- sample_sd / sqrt(n) # standard error
lower_90 <- sample_mean - (t90 * sample_se) # lower bound of 90% confidence interval
upper_90 <- sample_mean + (t90 * sample_se) # upper bound of 90% confidence interval
confint <- c(lower_90, upper_90)
confint # 90% confidence interval
table(yNew) # Checking Recoding
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
yNew <- y # Creating new variable for class year
# Converting the numbers to class year
yNew[y==1]<-"Freshman"
yNew[y==2]<-"Sophomore"
yNew[y==3]<-"Junior"
yNew[y==4]<-"Senior"
table(yNew) # Checking Recoding
expenditure <- read.table("expenditure.txt", header=T)
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c(),  pkgTest)
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1")
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t90 <- qt((1 - 0.9) / 2, lower.tail = FALSE, df = 24) # t-score for 90% confidence interval with 24 degrees of freedom
n <- length(y) # sample size
sample_mean <- mean(y) # sample mean
sample_sd <- sd(y) # sample standard deviation
sample_se <- sample_sd / sqrt(n) # standard error
lower_90 <- sample_mean - (t90 * sample_se) # lower bound of 90% confidence interval
upper_90 <- sample_mean + (t90 * sample_se) # upper bound of 90% confidence interval
confint <- c(lower_90, upper_90)
confint # 90% confidence interval
#####################
# Problem 2
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t.test(y, mu = 100) # Conducting one sample t-test
# Since the p-value of 0.5569 is greater than the alpha of 0.05, we fail to reject the Ho.
# We conclude that the true national mean IQ in schools is not significantly different from 100.
# We are 95% confident that the true national mean IQ in schools is between 93.04 and 103.84, and since
# 100 is included in this interval, there is not sufficient evidence to conclude that the true mean is
# significantly different from 100.
#####################
# Problem 3
#####################
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
yNew <- y # Creating new variable for class year
# Converting the numbers to class year
yNew[y==1]<-"Freshman"
yNew[y==2]<-"Sophomore"
yNew[y==3]<-"Junior"
yNew[y==4]<-"Senior"
table(yNew) # Checking Recoding
expenditure <- read.table("expenditure.txt", header=T)
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
# Plot Y vs. X1
expenditure <- read.table("expenditure.txt", header=T)
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c(),  pkgTest)
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1")
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t90 <- qt((1 - 0.9) / 2, lower.tail = FALSE, df = 24) # t-score for 90% confidence interval with 24 degrees of freedom
n <- length(y) # sample size
sample_mean <- mean(y) # sample mean
sample_sd <- sd(y) # sample standard deviation
sample_se <- sample_sd / sqrt(n) # standard error
lower_90 <- sample_mean - (t90 * sample_se) # lower bound of 90% confidence interval
upper_90 <- sample_mean + (t90 * sample_se) # upper bound of 90% confidence interval
confint <- c(lower_90, upper_90)
confint # 90% confidence interval
#####################
# Problem 2
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
t.test(y, mu = 100) # Conducting one sample t-test
# Since the p-value of 0.5569 is greater than the alpha of 0.05, we fail to reject the Ho.
# We conclude that the true national mean IQ in schools is not significantly different from 100.
# We are 95% confident that the true national mean IQ in schools is between 93.04 and 103.84, and since
# 100 is included in this interval, there is not sufficient evidence to conclude that the true mean is
# significantly different from 100.
#####################
# Problem 3
#####################
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
yNew <- y # Creating new variable for class year
# Converting the numbers to class year
yNew[y==1]<-"Freshman"
yNew[y==2]<-"Sophomore"
yNew[y==3]<-"Junior"
yNew[y==4]<-"Senior"
table(yNew) # Checking Recoding
expenditure <- read.table("expenditure.txt", header=T)
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
# Plot Y vs. X1
View(expenditure)
View(expenditure)
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region)
?boxplot
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, main = "Per Capita Expenditure on Public Education vs. Region", xlab = "", ylab = "")
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, main = "Per Capita Expenditure on Public Education vs. Region", xlab = "Region", ylab = "Per Capita Expenditure (dollars)")
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, main = "Per Capita Expenditure on Public Education vs. Geographical Region", xlab = "Geographical Region", ylab = "Per Capita Expenditure (dollars)")
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, main = "Expenditure on Public Education vs. Geographical Region", xlab = "Geographical Region", ylab = "Per Capita Expenditure (dollars)")
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, names = c("Northeast", "North Central", "South", "West"), main = "Expenditure on Public Education vs. Geographical Region", xlab = "Geographical Region", ylab = "Per Capita Expenditure (dollars)")
# Plot relationships between Y - X3 with scatterplots
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, names = c("Northeast", "North Central", "South", "West"), main = "Expenditure on Public Education vs. Geographical Region", xlab = "Geographical Region", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$Y, expenditure$X1)
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, main = )
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs region
boxplot(expenditure$Y ~ expenditure$Region, names = c("Northeast", "North Central", "South", "West"), main = "Expenditure on Public Education vs. Geographical Region", xlab = "Geographical Region", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
?plot
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, fill = expenditure$Region, main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
ggplot(expenditure, aes(X1, Y, colour = Region)) + geom_point()
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, log(Region), fill = expenditure$Region, main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, log(Region) main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, log(Region), main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, log(expenditure$Region), main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
plot(expenditure$X1, expenditure$Y, log(expenditure$Region), main = "Expenditure on Public Education vs. Personal Income", xlab = "Per Capita Personal Income (Dollars)", ylab = "Per Capita Expenditure (Dollars)")
# Plot Y vs. X1
?plot
